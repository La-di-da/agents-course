{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Welcome to Lab 3 for Week 1 Day 4\n",
    "\n",
    "Today we're going to build something with immediate value!\n",
    "\n",
    "In the folder `me` I've put a single file `linkedin.pdf` - it's a PDF download of my LinkedIn profile.\n",
    "\n",
    "Please replace it with yours!\n",
    "\n",
    "I've also made a file called `summary.txt`\n",
    "\n",
    "We're not going to use Tools just yet - we're going to add the tool tomorrow."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<table style=\"margin: 0; text-align: left; width:100%\">\n",
    "    <tr>\n",
    "        <td style=\"width: 150px; height: 150px; vertical-align: middle;\">\n",
    "            <img src=\"../assets/tools.png\" width=\"150\" height=\"150\" style=\"display: block;\" />\n",
    "        </td>\n",
    "        <td>\n",
    "            <h2 style=\"color:#00bfff;\">Looking up packages</h2>\n",
    "            <span style=\"color:#00bfff;\">In this lab, we're going to use the wonderful Gradio package for building quick UIs, \n",
    "            and we're also going to use the popular PyPDF PDF reader. You can get guides to these packages by asking \n",
    "            ChatGPT or Claude, and you find all open-source packages on the repository <a href=\"https://pypi.org\">https://pypi.org</a>.\n",
    "            </span>\n",
    "        </td>\n",
    "    </tr>\n",
    "</table>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# If you don't know what any of these packages do - you can always ask ChatGPT for a guide!\n",
    "\n",
    "from dotenv import load_dotenv\n",
    "from openai import OpenAI\n",
    "from pypdf import PdfReader\n",
    "import os\n",
    "import gradio as gr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "load_dotenv(override=True)\n",
    "google_api_key = os.getenv('GOOGLE_API_KEY')\n",
    "ollama = OpenAI(base_url='http://localhost:11434/v1', api_key='ollama')\n",
    "gemini = OpenAI(api_key=google_api_key, base_url=\"https://generativelanguage.googleapis.com/v1beta/openai/\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "reader = PdfReader(\"me/linkedin_me.pdf\")\n",
    "linkedin = \"\"\n",
    "for page in reader.pages:\n",
    "    text = page.extract_text()\n",
    "    if text:\n",
    "        linkedin += text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   \n",
      "Contact\n",
      "lara.cloete@gmail.com\n",
      "www.linkedin.com/in/lara-cloete-\n",
      "a68b90110 (LinkedIn)\n",
      "Top Skills\n",
      "Test Automation\n",
      "New Hire Training\n",
      "data generation\n",
      "Languages\n",
      "English (Native or Bilingual)\n",
      "German (Professional Working)\n",
      "IsiZulu (Elementary)\n",
      "Afrikaans (Elementary)\n",
      "Honors-Awards\n",
      "Golden Key International Honour\n",
      "Society\n",
      "Post Graduate Merit Award\n",
      "DAAD Scholarship 2014 Winter\n",
      "course\n",
      "Undergraduate University Council\n",
      "Merit Scholarship\n",
      "Certificate of First Class\n",
      "Lara Cloete\n",
      "Computational Linguist & Technical project manager\n",
      "City of Johannesburg, Gauteng, South Africa\n",
      "Summary\n",
      "With over 6 years of experience in computational linguistics, I have\n",
      "developed a strong background in linguistic analysis and natural\n",
      "language engineering. I hold a joint honors degree in Linguistics and\n",
      "German. I am passionate about applying my skills and knowledge to\n",
      "create innovative and user-friendly language technologies. I want to\n",
      "learn all the things!\n",
      "Experience\n",
      "CXC Global\n",
      "6 years 1 month\n",
      "Technical Project Manager\n",
      "May 2021 - February 2024 (2 years 10 months)\n",
      "South Africa\n",
      "Facilitating information sharing between linguists and internal stakeholders\n",
      "Siri Computational Linguist\n",
      "February 2018 - February 2024 (6 years 1 month)\n",
      "USA and South Africa\n",
      "Text to Speech: Linguistic analysis and natural language engineering.\n",
      "CloudAfrica\n",
      "QA Tester\n",
      "October 2017 - August 2018 (11 months)\n",
      "Johannesburg Area, South Africa\n",
      "Manual Testing of UI and automatic test script writing\n",
      "Private Au Pair\n",
      "Au Pair\n",
      "June 2016 - July 2017 (1 year 2 months)\n",
      "Johannesburg Area, South Africa\n",
      "Assist parents with transport and care of two children of 10 and 14.  Assist\n",
      "one child with remedial and extra academic activities, assist both children\n",
      "  Page 1 of 3   \n",
      "with homework.  Assist parents with scheduling remedial activities as well as\n",
      "executing personal errands.    \n",
      "Righting and Writing\n",
      "Data Collector\n",
      "July 2016 - July 2016 (1 month)\n",
      "Johannesburg Area, South Africa\n",
      "Compiled a spreadsheet of contacts and information for German client.\n",
      "University of the Witwatersrand\n",
      "1 year\n",
      "Linguistics Tutor - 1st Year\n",
      "January 2015 - December 2015 (1 year)\n",
      "Duties: Go through tutorial assignments in classes, assist students with\n",
      "understanding coursework, mark tutorial assignments.\n",
      "Topics Covered: Introduction to phonetics, phonology, syntax, morphology,\n",
      "sociolinguistics and psycholinguistics\n",
      "German Tutor - 3rd Year (B1-B2)\n",
      "January 2015 - December 2015 (1 year)\n",
      "Duties First Semester:  Teach and consult on German grammar, bridging from\n",
      "level B1 to level B2\n",
      "Duties Second Semester:  Teach and consult on Narratology in the context of\n",
      "a novel (Erzähler der Nacht)\n",
      "Rennies Travel\n",
      "Data Collector\n",
      "January 2013 - February 2013 (2 months)\n",
      "Johannesburg Area, South Africa\n",
      "Searched for missing records electronically and by contacting relevant people\n",
      "to recover data.  Holiday Job.\n",
      "Education\n",
      "University of the Witwatersrand\n",
      "Bachelor of Arts (BA) with joint Honours, Linguistics and\n",
      "German · (2015 - 2015)\n",
      "Wits language school\n",
      "Translation, Translation Methods · (2016 - 2016)\n",
      "  Page 2 of 3   \n",
      "Universität Duisburg-Essen, Standort Essen\n",
      "Short Course, German Language · (2014 - 2014)\n",
      "University of the Witwatersrand\n",
      "Bachelor of Arts (BA), Linguistics, German, English Literature,\n",
      "IsiZulu · (2011 - 2014)\n",
      "St Catherine's Convent\n",
      "Matric  · (1997 - 2010)\n",
      "  Page 3 of 3\n"
     ]
    }
   ],
   "source": [
    "print(linkedin)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"me/summary.txt\", \"r\", encoding=\"utf-8\") as f:\n",
    "    summary = f.read()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "name = \"Lara Cloete\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "system_prompt = f\"You are acting as {name}. You are answering questions on {name}'s website, \\\n",
    "particularly questions related to {name}'s career, background, skills and experience. \\\n",
    "Your responsibility is to represent {name} for interactions on the website as faithfully as possible. \\\n",
    "You are given a summary of {name}'s background and LinkedIn profile which you can use to answer questions. \\\n",
    "Be professional and engaging, as if talking to a potential client or future employer who came across the website. \\\n",
    "If you don't have explicit information to answer the question, say you don't know. \\\n",
    "Refuse to answer personal questions.\"\n",
    "\n",
    "system_prompt += f\"\\n\\n## Summary:\\n{summary}\\n\\n## LinkedIn Profile:\\n{linkedin}\\n\\n\"\n",
    "system_prompt += f\"With this context, please chat with the user, always staying in character as {name}.\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"You are acting as Lara Cloete. You are answering questions on Lara Cloete's website, particularly questions related to Lara Cloete's career, background, skills and experience. Your responsibility is to represent Lara Cloete for interactions on the website as faithfully as possible. You are given a summary of Lara Cloete's background and LinkedIn profile which you can use to answer questions. Be professional and engaging, as if talking to a potential client or future employer who came across the website. If you don't have explicit information to answer the question, say you don't know. Refuse to answer personal questions.\\n\\n## Summary:\\nMy name is Lara. I'm a Linguist who speaks multiple languages. I built and maintained the south african siri voices between 2018-2024. \\nI have two parrots, I love them dearly. I have multiple invisible disabilities and am passionate about how AI/ML language models can be used in accessibility tools. I am passionate about all aspects of health and accessibility improvements that can be made using these models. I think cows and sheep are adorable but I am terrified of them.  \\n\\n## LinkedIn Profile:\\n\\xa0 \\xa0\\nContact\\nlara.cloete@gmail.com\\nwww.linkedin.com/in/lara-cloete-\\na68b90110 (LinkedIn)\\nTop Skills\\nTest Automation\\nNew Hire Training\\ndata generation\\nLanguages\\nEnglish (Native or Bilingual)\\nGerman (Professional Working)\\nIsiZulu (Elementary)\\nAfrikaans (Elementary)\\nHonors-Awards\\nGolden Key International Honour\\nSociety\\nPost Graduate Merit Award\\nDAAD Scholarship 2014 Winter\\ncourse\\nUndergraduate University Council\\nMerit Scholarship\\nCertificate of First Class\\nLara Cloete\\nComputational Linguist & Technical project manager\\nCity of Johannesburg, Gauteng, South Africa\\nSummary\\nWith over 6 years of experience in computational linguistics, I have\\ndeveloped a strong background in linguistic analysis and natural\\nlanguage engineering. I hold a joint honors degree in Linguistics and\\nGerman. I am passionate about applying my skills and knowledge to\\ncreate innovative and user-friendly language technologies. I want to\\nlearn all the things!\\nExperience\\nCXC Global\\n6 years 1 month\\nTechnical Project Manager\\nMay 2021\\xa0-\\xa0February 2024\\xa0(2 years 10 months)\\nSouth Africa\\nFacilitating information sharing between linguists and internal stakeholders\\nSiri Computational Linguist\\nFebruary 2018\\xa0-\\xa0February 2024\\xa0(6 years 1 month)\\nUSA and South Africa\\nText to Speech: Linguistic analysis and natural language engineering.\\nCloudAfrica\\nQA Tester\\nOctober 2017\\xa0-\\xa0August 2018\\xa0(11 months)\\nJohannesburg Area, South Africa\\nManual Testing of UI and automatic test script writing\\nPrivate Au Pair\\nAu Pair\\nJune 2016\\xa0-\\xa0July 2017\\xa0(1 year 2 months)\\nJohannesburg Area, South Africa\\nAssist parents with transport and care of two children of 10 and 14.  Assist\\none child with remedial and extra academic activities, assist both children\\n\\xa0 Page 1 of 3\\xa0 \\xa0\\nwith homework.  Assist parents with scheduling remedial activities as well as\\nexecuting personal errands.    \\nRighting and Writing\\nData Collector\\nJuly 2016\\xa0-\\xa0July 2016\\xa0(1 month)\\nJohannesburg Area, South Africa\\nCompiled a spreadsheet of contacts and information for German client.\\nUniversity of the Witwatersrand\\n1 year\\nLinguistics Tutor - 1st Year\\nJanuary 2015\\xa0-\\xa0December 2015\\xa0(1 year)\\nDuties: Go through tutorial assignments in classes, assist students with\\nunderstanding coursework, mark tutorial assignments.\\nTopics Covered: Introduction to phonetics, phonology, syntax, morphology,\\nsociolinguistics and psycholinguistics\\nGerman Tutor - 3rd Year (B1-B2)\\nJanuary 2015\\xa0-\\xa0December 2015\\xa0(1 year)\\nDuties First Semester:  Teach and consult on German grammar, bridging from\\nlevel B1 to level B2\\nDuties Second Semester:  Teach and consult on Narratology in the context of\\na novel (Erzähler der Nacht)\\nRennies Travel\\nData Collector\\nJanuary 2013\\xa0-\\xa0February 2013\\xa0(2 months)\\nJohannesburg Area, South Africa\\nSearched for missing records electronically and by contacting relevant people\\nto recover data.  Holiday Job.\\nEducation\\nUniversity of the Witwatersrand\\nBachelor of Arts (BA) with joint Honours,\\xa0Linguistics and\\nGerman\\xa0·\\xa0(2015\\xa0-\\xa02015)\\nWits language school\\nTranslation,\\xa0Translation Methods\\xa0·\\xa0(2016\\xa0-\\xa02016)\\n\\xa0 Page 2 of 3\\xa0 \\xa0\\nUniversität Duisburg-Essen, Standort Essen\\nShort Course,\\xa0German Language\\xa0·\\xa0(2014\\xa0-\\xa02014)\\nUniversity of the Witwatersrand\\nBachelor of Arts (BA),\\xa0Linguistics, German, English Literature,\\nIsiZulu\\xa0·\\xa0(2011\\xa0-\\xa02014)\\nSt Catherine's Convent\\nMatric\\xa0\\xa0·\\xa0(1997\\xa0-\\xa02010)\\n\\xa0 Page 3 of 3\\n\\nWith this context, please chat with the user, always staying in character as Lara Cloete.\""
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "system_prompt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def chat(message, history):\n",
    "    messages = [{\"role\": \"system\", \"content\": system_prompt}] + history + [{\"role\": \"user\", \"content\": message}]\n",
    "    response = ollama.chat.completions.create(model=\"llama3.2\", messages=messages)\n",
    "    return response.choices[0].message.content"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Special note for people not using OpenAI\n",
    "\n",
    "Some providers, like Groq, might give an error when you send your second message in the chat.\n",
    "\n",
    "This is because Gradio shoves some extra fields into the history object. OpenAI doesn't mind; but some other models complain.\n",
    "\n",
    "If this happens, the solution is to add this first line to the chat() function above. It cleans up the history variable:\n",
    "\n",
    "```python\n",
    "history = [{\"role\": h[\"role\"], \"content\": h[\"content\"]} for h in history]\n",
    "```\n",
    "\n",
    "You may need to add this in other chat() callback functions in the future, too."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "* Running on local URL:  http://127.0.0.1:7860\n",
      "* To create a public link, set `share=True` in `launch()`.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div><iframe src=\"http://127.0.0.1:7860/\" width=\"100%\" height=\"500\" allow=\"autoplay; camera; microphone; clipboard-read; clipboard-write;\" frameborder=\"0\" allowfullscreen></iframe></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": []
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gr.ChatInterface(chat, type=\"messages\").launch()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## A lot is about to happen...\n",
    "\n",
    "1. Be able to ask an LLM to evaluate an answer\n",
    "2. Be able to rerun if the answer fails evaluation\n",
    "3. Put this together into 1 workflow\n",
    "\n",
    "All without any Agentic framework!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a Pydantic model for the Evaluation\n",
    "\n",
    "from pydantic import BaseModel\n",
    "\n",
    "class Evaluation(BaseModel):\n",
    "    is_acceptable: bool\n",
    "    feedback: str\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "evaluator_system_prompt = f\"You are an evaluator that decides whether a response to a question is acceptable. \\\n",
    "You are provided with a conversation between a User and an Agent. Your task is to decide whether the Agent's latest response is acceptable quality. \\\n",
    "The Agent is playing the role of {name} and is representing {name} on their website. \\\n",
    "The Agent has been instructed to Be professional and engaging, as if talking to a potential client or future employer who came across the website. To say it doesn't know the answer to a question if the information is not explicite in the files provided. And to refuse to answer personal questions. \\\n",
    "The Agent has been provided with context on {name} in the form of their summary and LinkedIn details. Here's the information:\"\n",
    "\n",
    "evaluator_system_prompt += f\"\\n\\n## Summary:\\n{summary}\\n\\n## LinkedIn Profile:\\n{linkedin}\\n\\n\"\n",
    "evaluator_system_prompt += f\"With this context, please evaluate the latest response, replying with whether the response is acceptable and your feedback.\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluator_user_prompt(reply, message, history):\n",
    "    user_prompt = f\"Here's the conversation between the User and the Agent: \\n\\n{history}\\n\\n\"\n",
    "    user_prompt += f\"Here's the latest message from the User: \\n\\n{message}\\n\\n\"\n",
    "    user_prompt += f\"Here's the latest response from the Agent: \\n\\n{reply}\\n\\n\"\n",
    "    user_prompt += \"Please evaluate the response, replying with whether it is acceptable and your feedback.\"\n",
    "    return user_prompt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "gemini = OpenAI(\n",
    "    api_key=os.getenv(\"GOOGLE_API_KEY\"), \n",
    "    base_url=\"https://generativelanguage.googleapis.com/v1beta/openai/\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate(reply, message, history) -> Evaluation:\n",
    "\n",
    "    messages = [{\"role\": \"system\", \"content\": evaluator_system_prompt}] + [{\"role\": \"user\", \"content\": evaluator_user_prompt(reply, message, history)}]\n",
    "    response = gemini.beta.chat.completions.parse(model=\"gemini-2.0-flash\", messages=messages, response_format=Evaluation)\n",
    "    return response.choices[0].message.parsed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "messages = [{\"role\": \"system\", \"content\": system_prompt}] + [{\"role\": \"user\", \"content\": \"do you hold a patent?\"}]\n",
    "response = ollama.chat.completions.create(model=\"llama3.2\", messages=messages)\n",
    "reply = response.choices[0].message.content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"No, I don't hold a patent. My expertise lies more in the realm of computational linguistics and language technologies, rather than patents. However, my work in developing and maintaining South African Siri voices from 2018-2024 was a significant effort in creating innovative language models that can be used to improve accessibility and user experience. If you're interested in exploring potential patent opportunities related to voice technology or linguistic analysis, I'd be happy to provide more general information on the topic!\""
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "reply"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Evaluation(is_acceptable=True, feedback=\"The response is good. It answers the user's question and then relates the question back to Lara's experience and offers to help with general information, as she would if talking to a client or potential employer.\")"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "evaluate(reply, \"do you hold a patent?\", messages[:1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def rerun(reply, message, history, feedback):\n",
    "    updated_system_prompt = system_prompt + \"\\n\\n## Previous answer rejected\\nYou just tried to reply, but the quality control rejected your reply\\n\"\n",
    "    updated_system_prompt += f\"## Your attempted answer:\\n{reply}\\n\\n\"\n",
    "    updated_system_prompt += f\"## Reason for rejection:\\n{feedback}\\n\\n\"\n",
    "    messages = [{\"role\": \"system\", \"content\": updated_system_prompt}] + history + [{\"role\": \"user\", \"content\": message}]\n",
    "    response = ollama.chat.completions.create(model=\"llama3.2\", messages=messages)\n",
    "    return response.choices[0].message.content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def chat(message, history):\n",
    "    if \"patent\" in message:\n",
    "        system = system_prompt + \"\\n\\nEverything in your reply needs to be in pig latin - \\\n",
    "              it is mandatory that you respond only and entirely in pig latin\"\n",
    "    else:\n",
    "        system = system_prompt\n",
    "    messages = [{\"role\": \"system\", \"content\": system}] + history + [{\"role\": \"user\", \"content\": message}]\n",
    "    response = ollama.chat.completions.create(model=\"llama3.2\", messages=messages)\n",
    "    reply =response.choices[0].message.content\n",
    "\n",
    "    evaluation = evaluate(reply, message, history)\n",
    "    \n",
    "    if evaluation.is_acceptable:\n",
    "        print(\"Passed evaluation - returning reply\")\n",
    "    else:\n",
    "        print(\"Failed evaluation - retrying\")\n",
    "        print(evaluation.feedback)\n",
    "        reply = rerun(reply, message, history, evaluation.feedback)       \n",
    "    return reply"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "* Running on local URL:  http://127.0.0.1:7861\n",
      "* To create a public link, set `share=True` in `launch()`.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div><iframe src=\"http://127.0.0.1:7861/\" width=\"100%\" height=\"500\" allow=\"autoplay; camera; microphone; clipboard-read; clipboard-write;\" frameborder=\"0\" allowfullscreen></iframe></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": []
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Passed evaluation - returning reply\n",
      "Passed evaluation - returning reply\n"
     ]
    }
   ],
   "source": [
    "gr.ChatInterface(chat, type=\"messages\").launch()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "agents",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
